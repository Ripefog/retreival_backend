# Video Retrieval Backend

Backend API cho há»‡ thá»‘ng tÃ¬m kiáº¿m video Ä‘a phÆ°Æ¡ng thá»©c vá»›i hybrid retrieval engine káº¿t há»£p CLIP vÃ  BEIT-3 models.

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend API   â”‚    â”‚   Milvus        â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Vector DB)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Elasticsearch  â”‚
                       â”‚  (Text Search)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

### 1. Hybrid Retrieval Engine
- **CLIP Model**: Semantic search vá»›i text-image matching
- **BEIT-3 Model**: Advanced vision-language model
- **Hybrid Approach**: Káº¿t há»£p cáº£ hai vá»›i "filter and refine" strategy

### 2. Multi-modal Search
- **Text Search**: Natural language queries
- **Object Detection**: Filter theo objects trong video
- **Color Filtering**: Filter theo mÃ u sáº¯c
- **OCR Search**: TÃ¬m kiáº¿m text trong images
- **ASR Search**: TÃ¬m kiáº¿m speech transcripts

### 3. Database Integration
- **Milvus**: Vector database cho embeddings
- **Elasticsearch**: Text search cho OCR/ASR
- **Ngrok Tunnels**: Remote access support

## ğŸ“¦ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.9+
- Docker (tÃ¹y chá»n)
- CUDA (tÃ¹y chá»n, cho GPU acceleration)

### 1. Clone repository
```bash
git clone <repository-url>
cd video-retrieval-backend
```

### 2. Táº¡o virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 4. Cáº¥u hÃ¬nh environment
Táº¡o file `.env`:
```env
# Milvus Configuration (via ngrok)
MILVUS_HOST=0.tcp.ap.ngrok.io
MILVUS_PORT=13216
MILVUS_ALIAS=default

# Elasticsearch Configuration (via ngrok)
ELASTICSEARCH_HOST=0.tcp.ap.ngrok.io
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USE_SSL=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Model Configuration
DEVICE=cuda  # hoáº·c cpu
```

## ğŸš€ Cháº¡y á»©ng dá»¥ng

### Development mode
```bash
cd app
python main.py
```

### Production mode
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Docker (tÃ¹y chá»n)
```bash
docker build -t video-retrieval-backend .
docker run -p 8000:8000 video-retrieval-backend
```

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /health
```
Response:
```json
{
  "status": "healthy",
  "milvus": {
    "status": "connected",
    "connected": true,
    "collections": {
      "arch_clip_image_v3": {
        "num_entities": 1000000,
        "loaded": true
      }
    }
  },
  "elasticsearch": {
    "status": "connected",
    "connected": true,
    "indices": {
      "video_retrieval_metadata_v3": {
        "exists": true,
        "doc_count": 500000
      }
    }
  },
  "retriever": "initialized"
}
```

### Text Search
```bash
POST /search
```
Request:
```json
{
  "text_query": "person walking in red shirt",
  "mode": "hybrid",
  "object_filters": ["person", "shirt"],
  "color_filters": ["red"],
  "ocr_query": "text in image",
  "asr_query": "speech content",
  "top_k": 100
}
```
Response:
```json
{
  "query": "person walking in red shirt",
  "mode": "hybrid",
  "results": [
    {
      "keyframe_id": "frame_000123",
      "video_id": "video_001",
      "timestamp": 45.2,
      "score": 0.95,
      "reasons": [
        "Matched query: person walking in red shirt",
        "Object filter: person",
        "Color filter: red",
        "Hybrid reranking applied"
      ],
      "metadata": {
        "rank": 1,
        "collection": "arch_clip_image_v3",
        "confidence": 0.95
      }
    }
  ],
  "total_results": 1,
  "search_time": 0.15
}
```

### Search Modes
```bash
GET /search/modes
```
Response:
```json
{
  "modes": ["hybrid", "clip", "beit3"],
  "descriptions": {
    "hybrid": "Káº¿t há»£p CLIP vÃ  BEIT-3 cho káº¿t quáº£ tá»‘t nháº¥t",
    "clip": "Chá»‰ sá»­ dá»¥ng CLIP model",
    "beit3": "Chá»‰ sá»­ dá»¥ng BEIT-3 model"
  }
}
```

### Collections Info
```bash
GET /collections
```
Response:
```json
{
  "collections": {
    "arch_clip_image_v3": {
      "num_entities": 1000000,
      "schema": "CollectionSchema(...)",
      "loaded": true
    },
    "arch_beit3_image_v3": {
      "num_entities": 1000000,
      "schema": "CollectionSchema(...)",
      "loaded": true
    }
  }
}
```

### Compare Search Modes
```bash
POST /search/compare
```
Request:
```json
{
  "text_query": "person walking",
  "top_k": 10
}
```
Response:
```json
{
  "query": "person walking",
  "comparison": {
    "hybrid": {
      "results": [...],
      "total_results": 10
    },
    "clip": {
      "results": [...],
      "total_results": 10
    },
    "beit3": {
      "results": [...],
      "total_results": 10
    }
  }
}
```

## ğŸ”§ Cáº¥u hÃ¬nh

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MILVUS_HOST` | Milvus host (via ngrok) | `0.tcp.ap.ngrok.io` |
| `MILVUS_PORT` | Milvus port | `13216` |
| `ELASTICSEARCH_HOST` | Elasticsearch host | `0.tcp.ap.ngrok.io` |
| `ELASTICSEARCH_PORT` | Elasticsearch port | `9200` |
| `DEVICE` | Device for models | `cuda` |
| `API_HOST` | API host | `0.0.0.0` |
| `API_PORT` | API port | `8000` |

### Collections Configuration

| Collection | Purpose | Description |
|------------|---------|-------------|
| `arch_clip_image_v3` | CLIP embeddings | Vector embeddings tá»« CLIP model |
| `arch_beit3_image_v3` | BEIT-3 embeddings | Vector embeddings tá»« BEIT-3 model |
| `arch_object_name_v3` | Object detection | Object labels vÃ  bounding boxes |
| `arch_color_name_v3` | Color detection | Color information |

### Indices Configuration

| Index | Purpose | Description |
|-------|---------|-------------|
| `video_retrieval_metadata_v3` | Video metadata | ThÃ´ng tin metadata cá»§a videos |
| `ocr` | OCR text | Text extracted tá»« images |
| `video_transcripts` | ASR transcripts | Speech transcripts |

## ğŸ” Search Pipeline

### 1. Initial Candidate Retrieval
- Encode text query thÃ nh vector
- Search trong Milvus collections
- Láº¥y top-k candidates

### 2. Object/Color Filtering
- Filter candidates theo object labels
- Filter theo color information
- Ãp dá»¥ng boolean logic

### 3. Text Filtering (OCR/ASR)
- Search trong Elasticsearch indices
- Filter theo OCR text matches
- Filter theo ASR transcript matches

### 4. Hybrid Reranking
- Káº¿t há»£p scores tá»« CLIP vÃ  BEIT-3
- Ãp dá»¥ng weighted combination
- Sort theo final scores

### 5. Result Formatting
- Format káº¿t quáº£ cuá»‘i cÃ¹ng
- ThÃªm metadata vÃ  reasons
- Return structured response

## ğŸ“Š Monitoring

### Health Checks
```bash
# Check API health
curl http://localhost:8000/health

# Check Milvus connection
curl http://localhost:8000/collections
```

### Logs
```bash
# View application logs
tail -f logs/app.log

# View error logs
tail -f logs/error.log
```

## ğŸš€ Deployment

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run with auto-reload
python app/main.py
```

### Production with Docker
```bash
# Build image
docker build -t video-retrieval-backend .

# Run container
docker run -d \
  -p 8000:8000 \
  -e MILVUS_HOST=your-milvus-host \
  -e ELASTICSEARCH_HOST=your-es-host \
  video-retrieval-backend
```

### Production with ngrok
```bash
# Install ngrok
pip install pyngrok

# Create tunnel
ngrok http 8000

# Update frontend URLs
export const API_URL = "https://your-ngrok-url";
```

## ğŸ”§ Development

### Project Structure
```
video-retrieval-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”œâ”€â”€ database.py          # Database connections
â”‚   â””â”€â”€ retrieval_engine.py  # Hybrid retriever
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # This file
â””â”€â”€ .env                    # Environment variables
```

### Adding New Features

1. **New Search Mode**:
   - Add mode to `SearchMode` enum in `models.py`
   - Implement logic in `retrieval_engine.py`
   - Update API endpoints in `main.py`

2. **New Filter Type**:
   - Add filter field to `SearchRequest` in `models.py`
   - Implement filtering logic in `retrieval_engine.py`
   - Update search pipeline

3. **New Database**:
   - Add connection logic in `database.py`
   - Update configuration in `config.py`
   - Add health checks

### Testing
```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=app tests/

# Run specific test
pytest tests/test_retrieval.py::test_search
```

## ğŸ› Troubleshooting

### Common Issues

1. **Milvus Connection Failed**
   ```bash
   # Check ngrok tunnel
   curl http://localhost:4040/api/tunnels
   
   # Check Milvus health
   curl http://localhost:8000/health
   ```

2. **Elasticsearch Connection Failed**
   ```bash
   # Check ES tunnel
   curl -k https://your-es-ngrok-url/_cluster/health
   
   # Check indices
   curl -k https://your-es-ngrok-url/_cat/indices
   ```

3. **Model Loading Failed**
   ```bash
   # Check GPU availability
   nvidia-smi
   
   # Check CUDA installation
   python -c "import torch; print(torch.cuda.is_available())"
   ```

### Performance Tuning

1. **GPU Acceleration**
   ```bash
   # Enable CUDA
   export DEVICE=cuda
   ```

2. **Batch Processing**
   ```python
   # Increase batch size
   BATCH_SIZE = 32
   ```

3. **Caching**
   ```python
   # Add Redis caching
   REDIS_URL = "redis://localhost:6379"
   ```

## ğŸ“ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“ Support

- **Issues**: [GitHub Issues](link-to-issues)
- **Email**: support@example.com
- **Documentation**: [Wiki](link-to-wiki)
- **Discord**: [Community](link-to-discord)

## ğŸ™ Acknowledgments

- [CLIP](https://github.com/openai/CLIP) - OpenAI's CLIP model
- [BEIT-3](https://github.com/microsoft/unilm/tree/master/beit3) - Microsoft's BEIT-3 model
- [Milvus](https://milvus.io/) - Vector database
- [Elasticsearch](https://www.elastic.co/) - Search engine
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework 